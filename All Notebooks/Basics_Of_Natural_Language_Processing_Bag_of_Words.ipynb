{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics Of Natural Language Processing Bag of Words.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiKxb1rC59rwbSFmote8UJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TusharNautiyal-web/CollabNotebooks/blob/main/All%20Notebooks/Basics_Of_Natural_Language_Processing_Bag_of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Natural Language Processing \n",
        "1. Tokenization\n",
        "2. Stemming\n",
        "3. Lematization\n",
        "4. Bag of Words"
      ],
      "metadata": {
        "id": "VpNIp2Dwho4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 Assing a Paragraph\n",
        "Paragraph is our corpus and we will be giving this corpus to tokenize and reduce it to important words.\n",
        "Tokenization is a way of separating a piece of text into smaller units called tokens. Here, tokens can be either words, characters, or subwords.\n"
      ],
      "metadata": {
        "id": "vSJdoYDTkXX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A Sentence From Geek For Geeks\n",
        "paragraph = '''\n",
        "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meanings to one word. \n",
        "Text preprocessing includes both Stemming as well as Lemmatization. \n",
        "Many times people find these two terms confusing. \n",
        "Some treat these two as the same. Actually, lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\n",
        "'''"
      ],
      "metadata": {
        "id": "aPKEEMWDhp4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 NLTK\n",
        "We are using NLTK Library to do Stemmming and tokeninzation. Lets Get Started."
      ],
      "metadata": {
        "id": "75KCNncQknrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer # For Stemming\n",
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1zhtH_khsFl",
        "outputId": "3fc29224-115a-40f3-a8d7-7a4cf4ccec73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Punkt has the feature tokenize so to use tokenization we need to download punk using below statement**\n",
        "\n",
        "***Also Download These Files***"
      ],
      "metadata": {
        "id": "tQQoj7sNkxl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b87d0Qq6iL_M",
        "outputId": "fb48a8ad-d26e-4699-bcf5-fb16dc3e2417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "cGnwr6KtiZPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAutWxnLijfQ",
        "outputId": "77cd0564-db1a-4abe-a62b-0d67f9e564f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\nLemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item.', 'Lemmatization is similar to stemming but it brings context to the words.', 'So it links words with similar meanings to one word.', 'Text preprocessing includes both Stemming as well as Lemmatization.', 'Many times people find these two terms confusing.', 'Some treat these two as the same.', 'Actually, lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3\n",
        "Now After doing tokenization we can either choose stemming or lematizing as we wish \n",
        "Stemming will not save the meaning of the words given to it whereas lematizer will now its upto you as per your usecase. But before lets do some pre-processing of our sentence \n",
        "\n",
        "To choose Lemmatizer or stemmer we use below code."
      ],
      "metadata": {
        "id": "74WWPZeCk8v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "uFmAs5q4ilNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is Stemming ?**\n",
        "\n",
        "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
      ],
      "metadata": {
        "id": "6CRHcSojj687"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmer.stem('thinking'))\n",
        "print(stemmer.stem('history'))\n",
        "print(stemmer.stem('going'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9QPhakljo6m",
        "outputId": "ca4174af-19a7-432e-9a78-c9e23f3a09e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "think\n",
            "histori\n",
            "go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets remove Special Characters and only take the words. For this we can use regular expression re.sub which will subtract everything other then a-z, A-Z"
      ],
      "metadata": {
        "id": "DOAT5ZChl1RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "corpus = []\n",
        "for i in range(len(sentences)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "metadata": {
        "id": "iFgK_WBVjybG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRNP_lgZmmA_",
        "outputId": "cd5261e9-08e1-4f3c-ba22-165abe5b032c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lemmatization process grouping together different inflected form word analyzed single item',\n",
              " 'lemmatization similar stemming brings context word',\n",
              " 'link word similar meaning one word',\n",
              " 'text preprocessing includes stemming well lemmatization',\n",
              " 'many time people find two term confusing',\n",
              " 'treat two',\n",
              " 'actually lemmatization preferred stemming lemmatization morphological analysis word']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets Apply Stemming\n",
        "1. We will take all sentences from corpus and tokenize them (Converting Sentence into Words)\n",
        "2. We will after that apply stemming on each word of tokenized sentence and also remove all stopwords.\n"
      ],
      "metadata": {
        "id": "g5aGo0dMm5ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx_m-kqAoW3R",
        "outputId": "56c8c7e5-c94a-4734-b14b-d7af79de67d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting All Sentences\n",
        "l1 = [] # This will take all words.\n",
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    # because we are reading english paragraph and stopwords can be duplicate so to not have any duplicates\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      l1.append(stemmer.stem(word))\n",
        "      print(stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQionCVhmwTy",
        "outputId": "c0383611-5f9c-49b4-d725-1033588485aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemmat\n",
            "process\n",
            "group\n",
            "togeth\n",
            "differ\n",
            "inflect\n",
            "form\n",
            "word\n",
            "analyz\n",
            "singl\n",
            "item\n",
            "lemmat\n",
            "similar\n",
            "stem\n",
            "bring\n",
            "context\n",
            "word\n",
            "link\n",
            "word\n",
            "similar\n",
            "mean\n",
            "one\n",
            "word\n",
            "text\n",
            "preprocess\n",
            "includ\n",
            "stem\n",
            "well\n",
            "lemmat\n",
            "mani\n",
            "time\n",
            "peopl\n",
            "find\n",
            "two\n",
            "term\n",
            "confus\n",
            "treat\n",
            "two\n",
            "actual\n",
            "lemmat\n",
            "prefer\n",
            "stem\n",
            "lemmat\n",
            "morpholog\n",
            "analysi\n",
            "word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ALso lets use Lemmatizer as we are trying to understand how Natural Language Processing is done.\n",
        "l2 = [] # This will contain Lematized words\n",
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      ans = lemmatizer.lemmatize(word)\n",
        "      l2.append(ans)\n"
      ],
      "metadata": {
        "id": "FkVv3GmxoRaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3v2Dpj0oe6_",
        "outputId": "139e11e8-acd9-414c-a0cb-a743b0f390eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lemmatization',\n",
              " 'process',\n",
              " 'grouping',\n",
              " 'together',\n",
              " 'different',\n",
              " 'inflected',\n",
              " 'form',\n",
              " 'word',\n",
              " 'analyzed',\n",
              " 'single',\n",
              " 'item',\n",
              " 'lemmatization',\n",
              " 'similar',\n",
              " 'stemming',\n",
              " 'brings',\n",
              " 'context',\n",
              " 'word',\n",
              " 'link',\n",
              " 'word',\n",
              " 'similar',\n",
              " 'meaning',\n",
              " 'one',\n",
              " 'word',\n",
              " 'text',\n",
              " 'preprocessing',\n",
              " 'includes',\n",
              " 'stemming',\n",
              " 'well',\n",
              " 'lemmatization',\n",
              " 'many',\n",
              " 'time',\n",
              " 'people',\n",
              " 'find',\n",
              " 'two',\n",
              " 'term',\n",
              " 'confusing',\n",
              " 'treat',\n",
              " 'two',\n",
              " 'actually',\n",
              " 'lemmatization',\n",
              " 'preferred',\n",
              " 'stemming',\n",
              " 'lemmatization',\n",
              " 'morphological',\n",
              " 'analysis',\n",
              " 'word']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Features \n",
        "\n",
        "Out of all This Data We will use bag of words technique. Below code is what u need to do. We will use count vectorizer to create features out of words."
      ],
      "metadata": {
        "id": "W104hkhDp4ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(binary = True)"
      ],
      "metadata": {
        "id": "4Z6z4L6Ppzt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = cv.fit_transform(corpus)\n",
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDOsDijxrH6y",
        "outputId": "0d6e58e4-44ab-48ba-c120-84077ea5ef87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'actually': 0,\n",
              " 'analysis': 1,\n",
              " 'analyzed': 2,\n",
              " 'brings': 3,\n",
              " 'confusing': 4,\n",
              " 'context': 5,\n",
              " 'different': 6,\n",
              " 'find': 7,\n",
              " 'form': 8,\n",
              " 'grouping': 9,\n",
              " 'includes': 10,\n",
              " 'inflected': 11,\n",
              " 'item': 12,\n",
              " 'lemmatization': 13,\n",
              " 'link': 14,\n",
              " 'many': 15,\n",
              " 'meaning': 16,\n",
              " 'morphological': 17,\n",
              " 'one': 18,\n",
              " 'people': 19,\n",
              " 'preferred': 20,\n",
              " 'preprocessing': 21,\n",
              " 'process': 22,\n",
              " 'similar': 23,\n",
              " 'single': 24,\n",
              " 'stemming': 25,\n",
              " 'term': 26,\n",
              " 'text': 27,\n",
              " 'time': 28,\n",
              " 'together': 29,\n",
              " 'treat': 30,\n",
              " 'two': 31,\n",
              " 'well': 32,\n",
              " 'word': 33}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HffYnYCBp4aQ",
        "outputId": "e500df25-da5b-4b50-8d02-02ab7bb2b27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lemmatization process grouping together different inflected form word analyzed single item'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzU3Mli7qgl7",
        "outputId": "9ec233ae-ef21-49f9-dc4c-d25092e8bc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "count_matrix = X.toarray()\n",
        "df = pd.DataFrame(data=count_matrix,columns = cv.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1pKh55Sqhm3",
        "outputId": "a71f67cf-bd29-4d09-bb09-3521093ef151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8i8TJ_AmyviW",
        "outputId": "d36eb4da-6035-4396-9327-126b1b9df073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   actually  analysis  analyzed  brings  confusing  context  different  find  \\\n",
              "0         0         0         1       0          0        0          1     0   \n",
              "1         0         0         0       1          0        1          0     0   \n",
              "2         0         0         0       0          0        0          0     0   \n",
              "3         0         0         0       0          0        0          0     0   \n",
              "4         0         0         0       0          1        0          0     1   \n",
              "\n",
              "   form  grouping  ...  single  stemming  term  text  time  together  treat  \\\n",
              "0     1         1  ...       1         0     0     0     0         1      0   \n",
              "1     0         0  ...       0         1     0     0     0         0      0   \n",
              "2     0         0  ...       0         0     0     0     0         0      0   \n",
              "3     0         0  ...       0         1     0     1     0         0      0   \n",
              "4     0         0  ...       0         0     1     0     1         0      0   \n",
              "\n",
              "   two  well  word  \n",
              "0    0     0     1  \n",
              "1    0     0     1  \n",
              "2    0     0     1  \n",
              "3    0     1     0  \n",
              "4    1     0     0  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5c316fc-7358-4694-a337-1aabbfa55eee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actually</th>\n",
              "      <th>analysis</th>\n",
              "      <th>analyzed</th>\n",
              "      <th>brings</th>\n",
              "      <th>confusing</th>\n",
              "      <th>context</th>\n",
              "      <th>different</th>\n",
              "      <th>find</th>\n",
              "      <th>form</th>\n",
              "      <th>grouping</th>\n",
              "      <th>...</th>\n",
              "      <th>single</th>\n",
              "      <th>stemming</th>\n",
              "      <th>term</th>\n",
              "      <th>text</th>\n",
              "      <th>time</th>\n",
              "      <th>together</th>\n",
              "      <th>treat</th>\n",
              "      <th>two</th>\n",
              "      <th>well</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5c316fc-7358-4694-a337-1aabbfa55eee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5c316fc-7358-4694-a337-1aabbfa55eee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5c316fc-7358-4694-a337-1aabbfa55eee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV5BeJWqywuO",
        "outputId": "078817e5-dbb1-4f75-cdfe-11f8e89d63ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['actually', 'analysis', 'analyzed', 'brings', 'confusing', 'context',\n",
              "       'different', 'find', 'form', 'grouping', 'includes', 'inflected',\n",
              "       'item', 'lemmatization', 'link', 'many', 'meaning', 'morphological',\n",
              "       'one', 'people', 'preferred', 'preprocessing', 'process', 'similar',\n",
              "       'single', 'stemming', 'term', 'text', 'time', 'together', 'treat',\n",
              "       'two', 'well', 'word'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**That's All For NLP Bag of Words**\n",
        "\n",
        "Which is a technique to convert text into features using count vectorizer. If you like such content subscribe to my youtube\n",
        "\n",
        "Youtube-Link: <a href = 'https://www.youtube.com/channel/UCsfYqXa3LoaLkB-9F2vmplA'>Click Here</a>\n",
        "\n",
        "Or Connect with me on linkedin.\n",
        "\n",
        "Linkedin: <a href = 'https://www.linkedin.com/in/tusharnautiyal/'>Click Here </a>\n",
        "\n",
        "@ author: Tushar Nautiyal\n",
        "Hope so you liked it 😀"
      ],
      "metadata": {
        "id": "0LTFmX1czBz2"
      }
    }
  ]
}